\chapter{Architecture Technique}

La réussite d'un projet d'ingénierie logicielle repose en grande partie sur la solidité et la pertinence de son architecture. Pour SearchBook, nous avons opté pour une architecture distribuée, modulaire et conteneurisée, garantissant à la fois la performance, la maintenabilité et la scalabilité du système. Ce chapitre détaille les choix technologiques effectués et la structure globale de l'application.

\section{Architecture Globale}

L'application suit le modèle classique et éprouvé de l'architecture \textbf{3-tiers} (Three-Tier Architecture), séparant clairement les responsabilités en trois couches distinctes :

\begin{enumerate}
    \item \textbf{La Couche Présentation (Frontend)} : C'est l'interface visible par l'utilisateur. Elle s'exécute dans le navigateur web (ou sur mobile) et est responsable de l'affichage des données et de la capture des interactions utilisateur. Elle ne contient aucune logique métier complexe ni accès direct aux données.
    \item \textbf{La Couche Application (Backend)} : C'est le cœur du système. Elle traite les requêtes provenant du frontend, exécute la logique métier (algorithmes de recherche, calculs de graphes), et interagit avec la base de données. Elle expose ses fonctionnalités via une API RESTful standardisée.
    \item \textbf{La Couche Données (Database)} : Elle assure la persistance et l'intégrité des données. Elle stocke les livres, les index inversés, et les structures de graphe nécessaires aux algorithmes.
\end{enumerate}

Cette séparation permet de développer, tester et déployer chaque composant indépendamment. De plus, l'utilisation de \textbf{Docker} et \textbf{Docker Compose} pour l'orchestration des conteneurs assure que l'environnement de développement est strictement identique à l'environnement de production, éliminant les problèmes de compatibilité ("It works on my machine").

\section{Choix Technologiques}

\subsection{Frontend : React et l'Écosystème Moderne}
Pour la couche présentation, nous avons choisi \textbf{React}, une bibliothèque JavaScript développée par Facebook. Ce choix est motivé par plusieurs facteurs :
\begin{itemize}
    \item \textbf{Composants Réutilisables} : React favorise une approche modulaire où l'interface est construite par assemblage de composants autonomes (barre de recherche, carte de livre, liste de résultats).
    \item \textbf{Virtual DOM} : React optimise les mises à jour de l'interface en minimisant les interactions coûteuses avec le DOM réel, ce qui est crucial pour afficher fluidement de longues listes de résultats de recherche.
    \item \textbf{TypeScript} : Nous avons couplé React avec TypeScript pour bénéficier du typage statique. Cela réduit considérablement les bugs à l'exécution et améliore la qualité du code grâce à l'autocomplétion et à la vérification des types lors du développement.
    \item \textbf{Vite} : Comme outil de build, Vite offre des temps de démarrage quasi-instantanés et un rechargement à chaud (HMR) très performant, accélérant le cycle de développement.
\end{itemize}

\subsection{Backend : FastAPI et Python}
Le choix de \textbf{Python} pour le backend s'est imposé naturellement pour sa richesse en bibliothèques de traitement de données et d'algorithmique. Pour le framework web, nous avons sélectionné \textbf{FastAPI} :
\begin{itemize}
    \item \textbf{Performance} : FastAPI est l'un des frameworks Python les plus rapides, rivalisant avec NodeJS et Go, grâce à son utilisation de Starlette et Pydantic.
    \item \textbf{Asynchronisme} : Il supporte nativement la programmation asynchrone (`async`/`await`), essentielle pour gérer de nombreuses requêtes simultanées sans bloquer le serveur, notamment lors des opérations d'E/S (lecture de base de données, requêtes réseau).
    \item \textbf{Documentation Automatique} : FastAPI génère automatiquement une documentation interactive (Swagger UI) de l'API, facilitant le test des endpoints et la collaboration avec l'équipe frontend.
\end{itemize}

Pour les calculs complexes liés aux graphes (centralité, suggestions), nous utilisons la bibliothèque \textbf{NetworkX}, référence dans le domaine de l'analyse de réseaux en Python.

\subsection{Base de Données : PostgreSQL}
Pour le stockage, \textbf{PostgreSQL} a été retenu pour sa robustesse et sa polyvalence :
\begin{itemize}
    \item \textbf{Fiabilité} : C'est un SGBD relationnel mature, garantissant l'intégrité des données (ACID).
    \item \textbf{Performance} : Il gère efficacement de gros volumes de données et supporte des indexations complexes.
    \item \textbf{Extensibilité} : Bien que nous utilisions principalement ses fonctionnalités relationnelles, sa capacité à gérer du JSON ou des extensions vectorielles offre des perspectives d'évolution intéressantes.
\end{itemize}

\section{Modélisation des Données}

La structure de la base de données est conçue pour optimiser à la fois le stockage et la récupération rapide d'informations.

\subsection{Table \texttt{books}}
Cette table est le référentiel central des ouvrages.
\begin{itemize}
    \item \texttt{id} (Primary Key) : Identifiant unique du livre.
    \item \texttt{title} : Titre de l'œuvre.
    \item \texttt{author} : Auteur.
    \item \texttt{content} : Texte intégral du livre (stocké pour l'affichage et l'analyse regex profonde).
    \item \texttt{gutenberg\_id} : Référence externe vers le projet Gutenberg.
    \item \texttt{closeness\_score} : Score de centralité pré-calculé pour le classement.
\end{itemize}

\subsection{Table \texttt{inverted\_index}}
C'est la pierre angulaire du moteur de recherche. Elle permet de passer d'un mot à la liste des documents qui le contiennent, sans avoir à parcourir tous les textes à chaque requête.
\begin{itemize}
    \item \texttt{word} : Le mot (lemme ou terme normalisé).
    \item \texttt{book\_id} (Foreign Key) : Référence vers le livre.
    \item \texttt{frequency} : Nombre d'occurrences du mot dans ce livre (utilisé pour le calcul de pertinence BM25).
    \item \texttt{positions} : Liste des positions du mot dans le texte (optionnel, mais utile pour la recherche de phrases ou la mise en évidence).
\end{itemize}
Un index B-Tree est placé sur la colonne \texttt{word} pour garantir une complexité de recherche logarithmique $O(\log N)$.

\subsection{Table \texttt{jaccard\_graph}}
Cette table matérialise le graphe de similarité entre les livres.
\begin{itemize}
    \item \texttt{book\_a\_id} : Premier livre.
    \item \texttt{book\_b\_id} : Second livre.
    \item \texttt{similarity\_score} : Valeur de l'indice de Jaccard (entre 0 et 1).
\end{itemize}
Seules les arêtes dont le score dépasse un certain seuil (défini lors de l'ingestion) sont stockées, afin de ne pas saturer la base avec des liens non pertinents.

\section{Flux de Données et Pipeline d'Ingestion}

L'architecture ne se limite pas aux composants statiques, elle définit aussi comment les données circulent. Le pipeline d'ingestion est un processus critique :
1.  \textbf{Extraction} : Le script \texttt{load\_books.py} télécharge les livres depuis Gutenberg ou lit les fichiers locaux.
2.  \textbf{Traitement} : Le texte est nettoyé (suppression des en-têtes, normalisation), tokenisé (découpage en mots), et filtré (stop-words).
3.  \textbf{Indexation} : Les fréquences de mots sont calculées et insérées dans \texttt{inverted\_index}.
4.  \textbf{Calcul de Graphe} : Une fois le corpus chargé, le système calcule les intersections de vocabulaire entre chaque paire de livres pour construire le graphe de Jaccard.
5.  \textbf{Analyse} : Les métriques de centralité sont calculées sur ce graphe et mises à jour dans la table \texttt{books}.

Cette architecture robuste constitue le socle sur lequel reposent les algorithmes avancés que nous détaillerons dans le chapitre suivant.
