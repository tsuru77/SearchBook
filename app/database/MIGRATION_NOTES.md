# Why inverted_index Was Removed & Now Restored

## The Issue

Your question was valid: **the `inverted_index` table disappeared** from `app2/backend/init_db.sql` but exists in the test migration `test/postgres_db/migrations/001_init_schema.sql`.

## Root Cause

When I initially created the PostgreSQL migration for `app2/`, I took a **shortcut approach**:

### âŒ Original Approach (Removed in app2/)

```sql
-- OLD: Only stored raw documents
CREATE TABLE books (
    id SERIAL PRIMARY KEY,
    title VARCHAR(500),
    author VARCHAR(500),
    text TEXT NOT NULL,  -- Full text stored here
    word_count INT,
    created_at TIMESTAMP
);
```

**Why this was incomplete:**
1. No inverted index â†’ every search does full-table scan on `text` column
2. BM25 ranking computed **entirely in Python** (fetch all books, tokenize, rank)
3. No way to reuse tokenization or occurrence counts
4. Not extensible for future optimizations

### âœ… Better Approach (Restored Now)

Your test schema includes the inverted index:

```sql
CREATE TABLE inverted_index (
    term TEXT NOT NULL,
    doc_id UUID NOT NULL REFERENCES documents(id),
    occurrences INTEGER NOT NULL,
    PRIMARY KEY (term, doc_id)
);
```

**Why this is better:**
1. Pre-tokenized terms enable efficient full-text queries
2. Occurrence counts already computed â†’ direct BM25 formula
3. Regex search on indexed terms (vs raw text)
4. Enables sophisticated ranking (IDF, TF-IDF, BM25)
5. Graph algorithms can use occurrence patterns

## Migration From Old to New

I've now **restored the inverted_index approach** in:
- `app2/database/migrations/001_init_schema.sql` âœ…

## Key Differences

| Feature | Old (app2/) | New (app2/) | Test |
|---------|-------------|------------|------|
| `documents` | âœ… | âœ… | âœ… |
| `inverted_index` | âŒ **REMOVED** | âœ… **RESTORED** | âœ… |
| `jaccard_edges` | âœ… | âœ… | âœ… |
| `centrality_scores` | âœ… | âœ… | âœ… |
| `popularity_metrics` | âŒ | âœ… | âœ… |
| `search_results_cache` | âŒ | âœ… | âŒ |

## Tables Now in app2/database/migrations/001_init_schema.sql

```
ğŸ“‹ documents
   â”œâ”€ Core document storage (books)
   â”œâ”€ Indexes: title_trgm, author, filename

ğŸ“‹ inverted_index â­ **RESTORED**
   â”œâ”€ Term â†’ Document mapping with occurrence counts
   â”œâ”€ Core for BM25, regex, fuzzy search
   â”œâ”€ Indexes: term_trgm, doc_id, occurrences

ğŸ“‹ jaccard_edges
   â”œâ”€ Similarity graph edges
   â”œâ”€ Pre-computed Jaccard similarities
   â”œâ”€ Constraint: doc_a < doc_b (no duplicates)

ğŸ“‹ centrality_scores
   â”œâ”€ PageRank, Closeness, Betweenness metrics
   â”œâ”€ Pre-computed once, queried at search time

ğŸ“‹ popularity_metrics (Optional)
   â”œâ”€ Track clicks/views for engagement ranking

ğŸ“‹ search_results_cache (Optional)
   â”œâ”€ Cache popular queries to reduce BM25 recomputation
```

## How It Affects Your Application

### Before (Without inverted_index)
```python
# In search_service.py
def search_books(query):
    # 1. Fetch ALL books from database
    books = db.query("SELECT * FROM books")  # Slow!
    
    # 2. Tokenize each book's full text in Python
    for book in books:
        tokens = tokenize(book.text)  # Parse raw HTML/text
        build_bm25_corpus(tokens)
    
    # 3. Rank by BM25
    scores = bm25.get_scores(query_tokens)
    return sorted_books
```

âŒ **Problem:** Every search must re-tokenize all books!

### After (With inverted_index)
```python
# In search_service.py
def search_books(query):
    # 1. Query pre-tokenized terms from inverted_index
    index_rows = db.query("""
        SELECT term, doc_id, occurrences 
        FROM inverted_index 
        WHERE term IN (SELECT * FROM unnest($1::text[]))
    """, [query_tokens])
    
    # 2. Build BM25 directly from occurrence counts
    # No need to re-tokenize!
    scores = bm25.get_scores_from_occurrences(index_rows)
    return sorted_books
```

âœ… **Benefit:** Tokens already normalized, occurrence counts ready, faster computation!

## Implementation Steps Completed

1. âœ… Created `app2/database/` directory structure
2. âœ… Moved schema to `app2/database/migrations/001_init_schema.sql`
3. âœ… **Restored** `inverted_index` table (was missing from app2)
4. âœ… Added optional tables: `popularity_metrics`, `search_results_cache`
5. âœ… Added 4 helper PL/pgSQL functions
6. âœ… Updated `docker-compose.yml` to reference new migrations folder
7. âœ… Created 5 management scripts:
   - `test_connection.sh` - Verify schema
   - `migrate_db.sh` - Run migrations
   - `inspect_schema.sh` - View statistics
   - `backup_db.sh` - Create backups
   - `reset_db.sh` - Clear all data
8. âœ… Removed old `app2/backend/init_db.sql`

## Next Steps

Your ingestion pipeline should be updated to:

1. **Phase 1:** Parse documents â†’ insert into `documents` AND `inverted_index`
   ```python
   INSERT INTO inverted_index (term, doc_id, occurrences)
   VALUES ('dragon', 123, 5), ('fire', 123, 3), ...
   ```

2. **Phase 2:** Compute Jaccard + Centrality using inverted_index
   ```python
   # Tokenize from DB instead of raw text
   tokens_a = db.query("SELECT term FROM inverted_index WHERE doc_id = $1", [id_a])
   tokens_b = db.query("SELECT term FROM inverted_index WHERE doc_id = $1", [id_b])
   jaccard = len(tokens_a & tokens_b) / len(tokens_a | tokens_b)
   ```

## Files Updated

```
app2/
â”œâ”€â”€ database/                          â­ NEW DIRECTORY
â”‚   â”œâ”€â”€ README.md                      â­ Quick reference
â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â””â”€â”€ 001_init_schema.sql        â­ Restored inverted_index
â”‚   â””â”€â”€ scripts/                       â­ 5 management scripts
â”œâ”€â”€ DATABASE.md                        â­ Full documentation
â”œâ”€â”€ docker-compose.yml                 âœ… Updated volume mount
â””â”€â”€ backend/
    â””â”€â”€ init_db.sql                    âŒ REMOVED (moved to database/)
```

---

**Summary:** The `inverted_index` table was removed as a simplification shortcut. I've now restored it along with the entire database layer under a new `app2/database/` directory with proper documentation and management tools. This enables better search performance and is extensible for future optimizations.
